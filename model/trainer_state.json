{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 30.0,
  "eval_steps": 500,
  "global_step": 75000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 3.096193552017212,
      "learning_rate": 4e-05,
      "loss": 0.61,
      "step": 500
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.7877345085144043,
      "learning_rate": 3e-05,
      "loss": 0.4508,
      "step": 1000
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.115236759185791,
      "learning_rate": 2e-05,
      "loss": 0.3392,
      "step": 1500
    },
    {
      "epoch": 0.8,
      "grad_norm": 6.135819911956787,
      "learning_rate": 1e-05,
      "loss": 0.3204,
      "step": 2000
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.23841401934623718,
      "learning_rate": 0.0,
      "loss": 0.3133,
      "step": 2500
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.773918867111206,
      "learning_rate": 2e-05,
      "loss": 0.2985,
      "step": 3000
    },
    {
      "epoch": 1.4,
      "grad_norm": 4.7207207679748535,
      "learning_rate": 1.5e-05,
      "loss": 0.2902,
      "step": 3500
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.5164921283721924,
      "learning_rate": 1e-05,
      "loss": 0.2834,
      "step": 4000
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.216322660446167,
      "learning_rate": 5e-06,
      "loss": 0.2779,
      "step": 4500
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.3397626876831055,
      "learning_rate": 0.0,
      "loss": 0.2801,
      "step": 5000
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.1865286827087402,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.2725,
      "step": 5500
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.338120222091675,
      "learning_rate": 1e-05,
      "loss": 0.2704,
      "step": 6000
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5409923195838928,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.2678,
      "step": 6500
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.6991440057754517,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.2639,
      "step": 7000
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8765129446983337,
      "learning_rate": 0.0,
      "loss": 0.2608,
      "step": 7500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.25754663348197937,
      "learning_rate": 1e-05,
      "loss": 0.2612,
      "step": 8000
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.5723228454589844,
      "learning_rate": 7.5e-06,
      "loss": 0.2554,
      "step": 8500
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.4123297929763794,
      "learning_rate": 5e-06,
      "loss": 0.2593,
      "step": 9000
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.4052310287952423,
      "learning_rate": 2.5e-06,
      "loss": 0.2529,
      "step": 9500
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.6334525346755981,
      "learning_rate": 0.0,
      "loss": 0.2536,
      "step": 10000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.47274500131607056,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.2512,
      "step": 10500
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.7348880767822266,
      "learning_rate": 6e-06,
      "loss": 0.2532,
      "step": 11000
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.5568259358406067,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.2467,
      "step": 11500
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.7987433671951294,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.2491,
      "step": 12000
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.582116961479187,
      "learning_rate": 0.0,
      "loss": 0.2432,
      "step": 12500
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.4886754751205444,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.246,
      "step": 13000
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.22124241292476654,
      "learning_rate": 5e-06,
      "loss": 0.2434,
      "step": 13500
    },
    {
      "epoch": 5.6,
      "grad_norm": 3.055760383605957,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.2396,
      "step": 14000
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.7336940169334412,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.2402,
      "step": 14500
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.3070024251937866,
      "learning_rate": 0.0,
      "loss": 0.2414,
      "step": 15000
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.35070744156837463,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.2379,
      "step": 15500
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.1381500959396362,
      "learning_rate": 4.285714285714286e-06,
      "loss": 0.2385,
      "step": 16000
    },
    {
      "epoch": 6.6,
      "grad_norm": 3.3802595138549805,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.2396,
      "step": 16500
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.34697455167770386,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 0.2359,
      "step": 17000
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.725444495677948,
      "learning_rate": 0.0,
      "loss": 0.2325,
      "step": 17500
    },
    {
      "epoch": 7.2,
      "grad_norm": 2.242483139038086,
      "learning_rate": 5e-06,
      "loss": 0.2339,
      "step": 18000
    },
    {
      "epoch": 7.4,
      "grad_norm": 2.229889154434204,
      "learning_rate": 3.75e-06,
      "loss": 0.2331,
      "step": 18500
    },
    {
      "epoch": 7.6,
      "grad_norm": 2.5201261043548584,
      "learning_rate": 2.5e-06,
      "loss": 0.2347,
      "step": 19000
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.3928931653499603,
      "learning_rate": 1.25e-06,
      "loss": 0.2312,
      "step": 19500
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.9987645149230957,
      "learning_rate": 0.0,
      "loss": 0.232,
      "step": 20000
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.27224624156951904,
      "learning_rate": 4.444444444444445e-06,
      "loss": 0.2283,
      "step": 20500
    },
    {
      "epoch": 8.4,
      "grad_norm": 3.384589910507202,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.227,
      "step": 21000
    },
    {
      "epoch": 8.6,
      "grad_norm": 3.71120023727417,
      "learning_rate": 2.2222222222222225e-06,
      "loss": 0.2305,
      "step": 21500
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.3349769413471222,
      "learning_rate": 1.1111111111111112e-06,
      "loss": 0.2312,
      "step": 22000
    },
    {
      "epoch": 9.0,
      "grad_norm": 3.6118035316467285,
      "learning_rate": 0.0,
      "loss": 0.2308,
      "step": 22500
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.3027297258377075,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.2267,
      "step": 23000
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.20019641518592834,
      "learning_rate": 3e-06,
      "loss": 0.2288,
      "step": 23500
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.9834965467453003,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.2278,
      "step": 24000
    },
    {
      "epoch": 9.8,
      "grad_norm": 4.131938934326172,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.2237,
      "step": 24500
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.9301795959472656,
      "learning_rate": 0.0,
      "loss": 0.2282,
      "step": 25000
    },
    {
      "epoch": 10.2,
      "grad_norm": 0.32509565353393555,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.2243,
      "step": 25500
    },
    {
      "epoch": 10.4,
      "grad_norm": 0.9210041761398315,
      "learning_rate": 2.7272727272727272e-06,
      "loss": 0.2249,
      "step": 26000
    },
    {
      "epoch": 10.6,
      "grad_norm": 0.11224956065416336,
      "learning_rate": 1.818181818181818e-06,
      "loss": 0.2239,
      "step": 26500
    },
    {
      "epoch": 10.8,
      "grad_norm": 3.3252110481262207,
      "learning_rate": 9.09090909090909e-07,
      "loss": 0.2305,
      "step": 27000
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.8852764964103699,
      "learning_rate": 0.0,
      "loss": 0.221,
      "step": 27500
    },
    {
      "epoch": 11.2,
      "grad_norm": 0.12010031193494797,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.2254,
      "step": 28000
    },
    {
      "epoch": 11.4,
      "grad_norm": 0.11538995802402496,
      "learning_rate": 2.5e-06,
      "loss": 0.2239,
      "step": 28500
    },
    {
      "epoch": 11.6,
      "grad_norm": 0.4102572798728943,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.2162,
      "step": 29000
    },
    {
      "epoch": 11.8,
      "grad_norm": 0.2559252977371216,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.2232,
      "step": 29500
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.2264556586742401,
      "learning_rate": 0.0,
      "loss": 0.2274,
      "step": 30000
    },
    {
      "epoch": 12.2,
      "grad_norm": 4.073801040649414,
      "learning_rate": 3.0769230769230774e-06,
      "loss": 0.2253,
      "step": 30500
    },
    {
      "epoch": 12.4,
      "grad_norm": 0.11683494597673416,
      "learning_rate": 2.307692307692308e-06,
      "loss": 0.221,
      "step": 31000
    },
    {
      "epoch": 12.6,
      "grad_norm": 0.7060996294021606,
      "learning_rate": 1.5384615384615387e-06,
      "loss": 0.2202,
      "step": 31500
    },
    {
      "epoch": 12.8,
      "grad_norm": 0.19977988302707672,
      "learning_rate": 7.692307692307694e-07,
      "loss": 0.2234,
      "step": 32000
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.22351141273975372,
      "learning_rate": 0.0,
      "loss": 0.2205,
      "step": 32500
    },
    {
      "epoch": 13.2,
      "grad_norm": 0.16836364567279816,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.2239,
      "step": 33000
    },
    {
      "epoch": 13.4,
      "grad_norm": 0.1066039577126503,
      "learning_rate": 2.142857142857143e-06,
      "loss": 0.2212,
      "step": 33500
    },
    {
      "epoch": 13.6,
      "grad_norm": 1.00947904586792,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 0.2172,
      "step": 34000
    },
    {
      "epoch": 13.8,
      "grad_norm": 0.0924956202507019,
      "learning_rate": 7.142857142857143e-07,
      "loss": 0.2232,
      "step": 34500
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.4128970205783844,
      "learning_rate": 0.0,
      "loss": 0.2173,
      "step": 35000
    },
    {
      "epoch": 14.2,
      "grad_norm": 0.16894514858722687,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.2208,
      "step": 35500
    },
    {
      "epoch": 14.4,
      "grad_norm": 1.5328867435455322,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.2189,
      "step": 36000
    },
    {
      "epoch": 14.6,
      "grad_norm": 0.30212560296058655,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.2225,
      "step": 36500
    },
    {
      "epoch": 14.8,
      "grad_norm": 0.41420087218284607,
      "learning_rate": 6.666666666666667e-07,
      "loss": 0.2196,
      "step": 37000
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.2067708522081375,
      "learning_rate": 0.0,
      "loss": 0.2167,
      "step": 37500
    },
    {
      "epoch": 15.2,
      "grad_norm": 0.22622911632061005,
      "learning_rate": 2.5e-06,
      "loss": 0.2218,
      "step": 38000
    },
    {
      "epoch": 15.4,
      "grad_norm": 0.15436461567878723,
      "learning_rate": 1.875e-06,
      "loss": 0.2209,
      "step": 38500
    },
    {
      "epoch": 15.6,
      "grad_norm": 0.11815442144870758,
      "learning_rate": 1.25e-06,
      "loss": 0.2172,
      "step": 39000
    },
    {
      "epoch": 15.8,
      "grad_norm": 4.445161819458008,
      "learning_rate": 6.25e-07,
      "loss": 0.2195,
      "step": 39500
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.15192273259162903,
      "learning_rate": 0.0,
      "loss": 0.2162,
      "step": 40000
    },
    {
      "epoch": 16.2,
      "grad_norm": 0.2057024985551834,
      "learning_rate": 2.3529411764705885e-06,
      "loss": 0.2126,
      "step": 40500
    },
    {
      "epoch": 16.4,
      "grad_norm": 0.15576624870300293,
      "learning_rate": 1.7647058823529412e-06,
      "loss": 0.2201,
      "step": 41000
    },
    {
      "epoch": 16.6,
      "grad_norm": 0.3092082142829895,
      "learning_rate": 1.1764705882352942e-06,
      "loss": 0.2171,
      "step": 41500
    },
    {
      "epoch": 16.8,
      "grad_norm": 5.821166515350342,
      "learning_rate": 5.882352941176471e-07,
      "loss": 0.2202,
      "step": 42000
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.27202901244163513,
      "learning_rate": 0.0,
      "loss": 0.2222,
      "step": 42500
    },
    {
      "epoch": 17.2,
      "grad_norm": 3.898111581802368,
      "learning_rate": 2.2222222222222225e-06,
      "loss": 0.2169,
      "step": 43000
    },
    {
      "epoch": 17.4,
      "grad_norm": 1.1710059642791748,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.2211,
      "step": 43500
    },
    {
      "epoch": 17.6,
      "grad_norm": 0.13379180431365967,
      "learning_rate": 1.1111111111111112e-06,
      "loss": 0.2147,
      "step": 44000
    },
    {
      "epoch": 17.8,
      "grad_norm": 0.1499110758304596,
      "learning_rate": 5.555555555555556e-07,
      "loss": 0.2198,
      "step": 44500
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.6975761651992798,
      "learning_rate": 0.0,
      "loss": 0.2168,
      "step": 45000
    },
    {
      "epoch": 18.2,
      "grad_norm": 0.17595654726028442,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.2179,
      "step": 45500
    },
    {
      "epoch": 18.4,
      "grad_norm": 0.16414760053157806,
      "learning_rate": 1.5789473684210528e-06,
      "loss": 0.2153,
      "step": 46000
    },
    {
      "epoch": 18.6,
      "grad_norm": 0.27485519647598267,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.2171,
      "step": 46500
    },
    {
      "epoch": 18.8,
      "grad_norm": 0.1462329924106598,
      "learning_rate": 5.263157894736843e-07,
      "loss": 0.218,
      "step": 47000
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.4621882438659668,
      "learning_rate": 0.0,
      "loss": 0.2179,
      "step": 47500
    },
    {
      "epoch": 19.2,
      "grad_norm": 0.07464559376239777,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.2175,
      "step": 48000
    },
    {
      "epoch": 19.4,
      "grad_norm": 0.09260604530572891,
      "learning_rate": 1.5e-06,
      "loss": 0.2153,
      "step": 48500
    },
    {
      "epoch": 19.6,
      "grad_norm": 0.28868192434310913,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.2181,
      "step": 49000
    },
    {
      "epoch": 19.8,
      "grad_norm": 0.20712095499038696,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.2156,
      "step": 49500
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.5414321422576904,
      "learning_rate": 0.0,
      "loss": 0.2173,
      "step": 50000
    },
    {
      "epoch": 20.2,
      "grad_norm": 0.1647062450647354,
      "learning_rate": 1.9047619047619051e-06,
      "loss": 0.2192,
      "step": 50500
    },
    {
      "epoch": 20.4,
      "grad_norm": 0.2652297914028168,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 0.2149,
      "step": 51000
    },
    {
      "epoch": 20.6,
      "grad_norm": 0.14328789710998535,
      "learning_rate": 9.523809523809526e-07,
      "loss": 0.2131,
      "step": 51500
    },
    {
      "epoch": 20.8,
      "grad_norm": 0.3763647675514221,
      "learning_rate": 4.761904761904763e-07,
      "loss": 0.2142,
      "step": 52000
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.11366355419158936,
      "learning_rate": 0.0,
      "loss": 0.2207,
      "step": 52500
    },
    {
      "epoch": 21.2,
      "grad_norm": 1.6116790771484375,
      "learning_rate": 1.818181818181818e-06,
      "loss": 0.2148,
      "step": 53000
    },
    {
      "epoch": 21.4,
      "grad_norm": 5.21912956237793,
      "learning_rate": 1.3636363636363636e-06,
      "loss": 0.2198,
      "step": 53500
    },
    {
      "epoch": 21.6,
      "grad_norm": 0.1707037389278412,
      "learning_rate": 9.09090909090909e-07,
      "loss": 0.2148,
      "step": 54000
    },
    {
      "epoch": 21.8,
      "grad_norm": 0.11087862402200699,
      "learning_rate": 4.545454545454545e-07,
      "loss": 0.2145,
      "step": 54500
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.5190677046775818,
      "learning_rate": 0.0,
      "loss": 0.2152,
      "step": 55000
    },
    {
      "epoch": 22.2,
      "grad_norm": 0.17444251477718353,
      "learning_rate": 1.7391304347826088e-06,
      "loss": 0.2167,
      "step": 55500
    },
    {
      "epoch": 22.4,
      "grad_norm": 0.22835968434810638,
      "learning_rate": 1.3043478260869564e-06,
      "loss": 0.2135,
      "step": 56000
    },
    {
      "epoch": 22.6,
      "grad_norm": 0.23493549227714539,
      "learning_rate": 8.695652173913044e-07,
      "loss": 0.216,
      "step": 56500
    },
    {
      "epoch": 22.8,
      "grad_norm": 0.11487311124801636,
      "learning_rate": 4.347826086956522e-07,
      "loss": 0.2155,
      "step": 57000
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.331018328666687,
      "learning_rate": 0.0,
      "loss": 0.2156,
      "step": 57500
    },
    {
      "epoch": 23.2,
      "grad_norm": 0.409166157245636,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.2157,
      "step": 58000
    },
    {
      "epoch": 23.4,
      "grad_norm": 0.15364515781402588,
      "learning_rate": 1.25e-06,
      "loss": 0.2149,
      "step": 58500
    },
    {
      "epoch": 23.6,
      "grad_norm": 0.27102336287498474,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.2154,
      "step": 59000
    },
    {
      "epoch": 23.8,
      "grad_norm": 0.2629011869430542,
      "learning_rate": 4.1666666666666667e-07,
      "loss": 0.2128,
      "step": 59500
    },
    {
      "epoch": 24.0,
      "grad_norm": 3.501636028289795,
      "learning_rate": 0.0,
      "loss": 0.2163,
      "step": 60000
    },
    {
      "epoch": 24.2,
      "grad_norm": 0.11672881990671158,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.2168,
      "step": 60500
    },
    {
      "epoch": 24.4,
      "grad_norm": 0.1826987862586975,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.2156,
      "step": 61000
    },
    {
      "epoch": 24.6,
      "grad_norm": 0.1577153503894806,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.2156,
      "step": 61500
    },
    {
      "epoch": 24.8,
      "grad_norm": 0.11393772065639496,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.2131,
      "step": 62000
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.29301977157592773,
      "learning_rate": 0.0,
      "loss": 0.212,
      "step": 62500
    },
    {
      "epoch": 25.2,
      "grad_norm": 0.051753345876932144,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.2271,
      "step": 63000
    },
    {
      "epoch": 25.4,
      "grad_norm": 0.08872324228286743,
      "learning_rate": 7.666666666666667e-06,
      "loss": 0.2246,
      "step": 63500
    },
    {
      "epoch": 25.6,
      "grad_norm": 0.07724624127149582,
      "learning_rate": 7.333333333333334e-06,
      "loss": 0.2316,
      "step": 64000
    },
    {
      "epoch": 25.8,
      "grad_norm": 0.10668523609638214,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.2335,
      "step": 64500
    },
    {
      "epoch": 26.0,
      "grad_norm": 10.347270965576172,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.2259,
      "step": 65000
    },
    {
      "epoch": 26.2,
      "grad_norm": 0.04827488213777542,
      "learning_rate": 6.333333333333334e-06,
      "loss": 0.2259,
      "step": 65500
    },
    {
      "epoch": 26.4,
      "grad_norm": 0.1518077552318573,
      "learning_rate": 6e-06,
      "loss": 0.2253,
      "step": 66000
    },
    {
      "epoch": 26.6,
      "grad_norm": 1.7395597696304321,
      "learning_rate": 5.666666666666667e-06,
      "loss": 0.2206,
      "step": 66500
    },
    {
      "epoch": 26.8,
      "grad_norm": 0.07470568269491196,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.2227,
      "step": 67000
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.2628220319747925,
      "learning_rate": 5e-06,
      "loss": 0.2191,
      "step": 67500
    },
    {
      "epoch": 27.2,
      "grad_norm": 1.4671516418457031,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.2262,
      "step": 68000
    },
    {
      "epoch": 27.4,
      "grad_norm": 0.06481222063302994,
      "learning_rate": 4.333333333333334e-06,
      "loss": 0.215,
      "step": 68500
    },
    {
      "epoch": 27.6,
      "grad_norm": 0.15894019603729248,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.2205,
      "step": 69000
    },
    {
      "epoch": 27.8,
      "grad_norm": 0.49697038531303406,
      "learning_rate": 3.666666666666667e-06,
      "loss": 0.2196,
      "step": 69500
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.24222035706043243,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.22,
      "step": 70000
    },
    {
      "epoch": 28.2,
      "grad_norm": 0.055422987788915634,
      "learning_rate": 3e-06,
      "loss": 0.2178,
      "step": 70500
    },
    {
      "epoch": 28.4,
      "grad_norm": 8.601033210754395,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.2177,
      "step": 71000
    },
    {
      "epoch": 28.6,
      "grad_norm": 0.05439634248614311,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 0.2192,
      "step": 71500
    },
    {
      "epoch": 28.8,
      "grad_norm": 0.0738353356719017,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.2184,
      "step": 72000
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.16663235425949097,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.2165,
      "step": 72500
    },
    {
      "epoch": 29.2,
      "grad_norm": 3.9310967922210693,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.221,
      "step": 73000
    },
    {
      "epoch": 29.4,
      "grad_norm": 0.11677055805921555,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.216,
      "step": 73500
    },
    {
      "epoch": 29.6,
      "grad_norm": 0.10127467662096024,
      "learning_rate": 6.666666666666667e-07,
      "loss": 0.2202,
      "step": 74000
    },
    {
      "epoch": 29.8,
      "grad_norm": 0.032493751496076584,
      "learning_rate": 3.3333333333333335e-07,
      "loss": 0.2144,
      "step": 74500
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.6470026969909668,
      "learning_rate": 0.0,
      "loss": 0.2137,
      "step": 75000
    }
  ],
  "logging_steps": 500,
  "max_steps": 75000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.74549055045632e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
